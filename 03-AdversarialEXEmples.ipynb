{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Adversarial EXEmples: evasion attacks against Windows malware detectors\n",
    "\n",
    "In this laboratory, you will learn how to use SecML to create adversarial examples against Windows malware detector implemented through machine learning techniques. To do so, we will use [SecML malware](https://github.com/pralab/secml_malware), a SecML plugin containing most of the strategies developed to evade detectors.\n",
    "\n",
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](\n",
    "https://colab.research.google.com/github/fabiogueunige/Trustworthy/blob/HEAD/03-AdversarialEXEmples.ipynb)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "try:\n",
    "    import secml_malware\n",
    "except ImportError:\n",
    "    %pip install git+https://github.com/elastic/ember.git\n",
    "    %pip install secml-malware"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# The Windows PE file format\n",
    "Before starting the explanations of attacks, we remind how Windows programs are stored as file, following the [Windows Portable Executable (PE)](https://learn.microsoft.com/en-us/windows/win32/debug/pe-format) file format.\n",
    "There are tons of Python libraries for dissecting programs, one of the best is [lief](https://github.com/lief-project/LIEF).\n",
    "The latter is also used inside `secml-malware` to perturb samples, as shown later on in this tutorial.\n",
    "Opening an executable is straight-forward:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import lief\n",
    "\n",
    "exe_path = 'exe/calc.exe'\n",
    "exe_object: lief.PE = lief.parse(exe_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Now, the `exe_object` contains all the information of the loaded program.\n",
    "We can look for all the components. For instance, here is how you can read the header metadata:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "print('DOS Header')\n",
    "print(exe_object.dos_header)\n",
    "\n",
    "print('PE Header')\n",
    "print(exe_object.header)\n",
    "\n",
    "print('Optional Header')\n",
    "print(exe_object.optional_header)\n",
    "\n",
    "print('Sections')\n",
    "for s in exe_object.sections:\n",
    "    print(s.name, s.characteristics_lists)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "This library is also very useful for manipulating the EXEs.\n",
    "For instance, in few lines of code you can add sections to a program."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Importa la libreria LIEF per manipolare file PE (Portable Executable)\n",
    "import lief\n",
    "\n",
    "# Crea una nuova sezione PE. La dimensione del nome della sezione è limitata a 8 byte.\n",
    "new_section : lief.PE.Section = lief.PE.Section()\n",
    "\n",
    "# Assegna il nome alla nuova sezione\n",
    "new_section.name = '.newsec'\n",
    "\n",
    "# Imposta il contenuto della nuova sezione come una lista di valori ASCII dei caratteri nella stringa\n",
    "new_section.content = [ord(i) for i in \"This is my newly created section\"]\n",
    "\n",
    "# Imposta le caratteristiche della sezione, in questo caso la sezione è scartabile dalla memoria\n",
    "new_section.characteristics = lief.PE.SECTION_CHARACTERISTICS.MEM_DISCARDABLE\n",
    "\n",
    "# Aggiunge la nuova sezione all'oggetto PE esistente\n",
    "exe_object.add_section(new_section)\n",
    "\n",
    "# Crea un costruttore PE per ricostruire il binario con la nuova sezione\n",
    "builder = lief.PE.Builder(exe_object)\n",
    "\n",
    "# Costruisce il nuovo binario\n",
    "builder.build()\n",
    "\n",
    "# Analizza il binario appena costruito per ottenere l'oggetto PE aggiornato\n",
    "exe_object = lief.PE.parse(builder.get_build())\n",
    "\n",
    "# Stampa i nomi delle sezioni e le loro caratteristiche\n",
    "print('Sections')\n",
    "for s in exe_object.sections:\n",
    "    print(s.name, s.characteristics_lists)\n",
    "\n",
    "# Scrive il nuovo binario su un file\n",
    "builder.write('new_exe.file')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "As you can see, the new section appeared as last one.\n",
    "More information on how to use lief on the [documentation of the library](https://lief-project.github.io/doc/stable/index.html)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Evasion of End-to-end Deep Neural Network for Malware Detection\n",
    "\n",
    "In this tutorial, you will learn how to use this plugin to test the already implemented attacks against a PyTorch network of your choice.\n",
    "We first instantiate a deep neural network trained on raw bytes, called MalConv, and we pass it to SecML Malware."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Importa il modulo os per interagire con il sistema operativo\n",
    "import os\n",
    "\n",
    "# Importa il modulo magic per identificare i tipi di file\n",
    "import magic\n",
    "\n",
    "# Importa CArray dalla libreria secml per la manipolazione di array\n",
    "from secml.array import CArray\n",
    "\n",
    "# Importa il modello MalConv dalla libreria secml_malware\n",
    "from secml_malware.models.malconv import MalConv\n",
    "\n",
    "# Importa CClassifierEnd2EndMalware e End2EndModel dalla libreria secml_malware\n",
    "# CClassifierEnd2EndMalware è un modello che prende un dispositivo e restituisce un output\n",
    "from secml_malware.models.c_classifier_end2end_malware import CClassifierEnd2EndMalware, End2EndModel\n",
    "\n",
    "# Crea un'istanza del modello MalConv (Malware Convolution, un modello basato su pytorch)\n",
    "net = MalConv()\n",
    "\n",
    "# Avvolge il modello MalConv con CClassifierEnd2EndMalware per creare un modello end-to-end\n",
    "net = CClassifierEnd2EndMalware(net)\n",
    "\n",
    "# Carica il modello pre-addestrato e aggiunge anche un po' di padding all'input\n",
    "net.load_pretrained_model()\n",
    "\n",
    "# Stampa la rappresentazione del modello caricato\n",
    "print(net)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Firstly, we have created the network (MalConv) and it has been passed wrapped with a *CClassifierEnd2EndMalware* model class.\n",
    "This object generalizes PyTorch end-to-end ML models.\n",
    "Since MalConv is already coded inside the plugin, the weights are also stored, and they can be retrieved with the *load_pretrained_model* method.\n",
    "\n",
    "If you wish to use diffierent weights, pass the path to the PyTorch *pth* file to that method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from secml_malware.attack.whitebox.c_header_evasion import CHeaderEvasion # Attack Dos Header\n",
    "\n",
    "# Load the malware sample to be attacked \n",
    "partial_dos = CHeaderEvasion(net, random_init=False, iterations=10, optimize_all_dos=False, threshold=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "This is how an attack is created, no further action is needed.\n",
    "The `random_init` parameter specifies if the bytes should be assigned with random values before beginning the optimization process, `iterations` sets the number of steps of the attack, `optimize_all_dos` sets if all the DOS header should be perturbed, or just the first 58 bytes, while `threshold` is the detection threshold used as a stopping condition.\n",
    "\n",
    "If you want to see how much the network is deteriorated by the attack, set this parameter to 0, or it will stop as soon as the confidence decreases below such value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Definisce la cartella contenente i file eseguibili\n",
    "folder = \"exe\"\n",
    "\n",
    "# Inizializza le liste per i dati di input, le etichette e i nomi dei file\n",
    "X = []\n",
    "y = []\n",
    "file_names = []\n",
    "\n",
    "# Itera su tutti i file nella cartella specificata\n",
    "for i, f in enumerate(os.listdir(folder)):\n",
    "    # Costruisce il percorso completo del file\n",
    "    path = os.path.join(folder, f)\n",
    "    \n",
    "    # Verifica se il percorso è un file, altrimenti continua con il prossimo file\n",
    "    if not os.path.isfile(path):\n",
    "        continue\n",
    "    \n",
    "    # Verifica se il file è un eseguibile PE32, altrimenti continua con il prossimo file\n",
    "    if \"PE32\" not in magic.from_file(path):\n",
    "        continue\n",
    "    \n",
    "    # Legge il contenuto del file in modalità binaria\n",
    "    with open(path, \"rb\") as file_handle:\n",
    "        code = file_handle.read()\n",
    "    \n",
    "    # Converte il contenuto del file in un array numpy utilizzando il modello end-to-end\n",
    "    x = End2EndModel.bytes_to_numpy(\n",
    "        code, net.get_input_max_length(), 256, False\n",
    "    )\n",
    "    \n",
    "    # Predice la probabilità di malware e ottiene la confidenza\n",
    "    _, confidence = net.predict(CArray(x), True)\n",
    "\n",
    "    # Se la confidenza è inferiore a 0.5, continua con il prossimo file\n",
    "    if confidence[0, 1].item() < 0.5:\n",
    "        continue\n",
    "\n",
    "    # Stampa il nome del file aggiunto e la sua confidenza\n",
    "    print(f\"> Added {f} with confidence {confidence[0,1].item()}\")\n",
    "    \n",
    "    # Aggiunge l'array numpy alla lista degli input\n",
    "    X.append(x)\n",
    "    \n",
    "    # Aggiunge la confidenza alla lista delle etichette\n",
    "    conf = confidence[1][0].item()\n",
    "    y.append([1 - conf, conf])\n",
    "    \n",
    "    # Aggiunge il percorso del file alla lista dei nomi dei file\n",
    "    file_names.append(path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "We load a simple dataset from the provided `exe` that you have filled with malware to test the attacks.\n",
    "Since we are dealing with SecML, we need to load all the programs inside as CArrays.\n",
    "Once we have built the dataset, we can run the instantiated attack.  \n",
    "Model if not heck the overfitting than very bad (decision trees are more robust)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Showed part\n",
    "for sample, label in zip(X, y):\n",
    "    # run the attack\n",
    "    y_pred, adv_score, adv_ds, f_obj = partial_dos.run(CArray(sample), CArray(label[1]))\n",
    "    # return the probabilities of the attack (know how fast reduce the confidence of the attack)\n",
    "    print(partial_dos.confidences_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# plotting the confidence of the attack\n",
    "plt.plot(partial_dos.confidences_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Inside the `adv_ds` object, you can find the adversarial example computed by the attack.\n",
    "You can reconstruct the functioning example by using a specific function inside the plugin."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Ottiene il primo esempio avversario dal dataset avversario\n",
    "adv_x = adv_ds.X[0, :]\n",
    "\n",
    "# Crea un campione reale dall'esempio avversario utilizzando il file originale\n",
    "real_adv_x = partial_dos.create_real_sample_from_adv(file_names[0], adv_x)\n",
    "\n",
    "# Stampa la lunghezza del campione reale avversario\n",
    "print(len(real_adv_x))\n",
    "\n",
    "# Converte il campione reale avversario in un array numpy utilizzando il modello end-to-end\n",
    "real_x = End2EndModel.bytes_to_numpy(real_adv_x, net.get_input_max_length(), 256, False)\n",
    "\n",
    "# Predice la probabilità di malware e ottiene la confidenza per il campione reale avversario\n",
    "_, confidence = net.predict(CArray(real_x), True)\n",
    "\n",
    "# Stampa la confidenza del campione reale avversario\n",
    "print(confidence[0, 1].item())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "... and you're done!\n",
    "If you want to create a real sample (stored on disk), just have a look at the `create_real_sample_from_adv` of each attack. It accepts a third string argument that will be used as a destination file path for storing the adversarial example."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "We used one attack, which is the Partial DOS one. But what if we want to use others?\n",
    "SecML malware is shipped with different attacking strategies, that can be easily created similarly to the DOS Header attack. A complete list of them can be found in the [source code](https://github.com/pralab/secml_malware/tree/master/secml_malware/attack/whitebox) or the [documentation](https://secml-malware.readthedocs.io/en/docs/source/secml_malware.attack.whitebox.html) of the other white box attacks.\n",
    "To give you a practical example, we now use an attack that append bytes at the end of the file (padding) and replace unusued space between sections (slack), and it leverages an iterative version of [FGSM attack](https://arxiv.org/abs/1802.04528) to optimize the byte values of executables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "is_executing": true
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Importa l'attacco whitebox CKreukEvasion dalla libreria secml_malware\n",
    "from secml_malware.attack.whitebox import CKreukEvasion\n",
    "\n",
    "# Crea un'istanza dell'attacco CKreukEvasion con i parametri specificati\n",
    "ifgsm = CKreukEvasion(net, how_many_padding_bytes=58, epsilon=1.0, iterations=10, threshold=0)\n",
    "\n",
    "# Itera su ogni campione e etichetta nei dati di input e nelle etichette\n",
    "for i, (sample, label) in enumerate(zip(X, y)):\n",
    "    # Esegue l'attacco IFGSM sul campione e ottiene la previsione, il punteggio avversario, il dataset avversario e l'oggetto funzione\n",
    "    y_pred, adv_score, adv_ds, f_obj = ifgsm.run(CArray(sample), CArray(label[1]))\n",
    "    \n",
    "    # Stampa le confidenze dell'attacco\n",
    "    print(ifgsm.confidences_)\n",
    "    \n",
    "    # Crea un campione reale dall'esempio avversario utilizzando il file originale\n",
    "    real_adv_x = ifgsm.create_real_sample_from_adv(file_names[i], adv_ds.X[i, :])\n",
    "    \n",
    "    # Legge e stampa la lunghezza del file originale\n",
    "    with open(file_names[i], 'rb') as f:\n",
    "        print('Original length: ', len(f.read()))\n",
    "    \n",
    "    # Stampa la lunghezza del campione avversario reale\n",
    "    print('Adversarial sample length: ', len(real_adv_x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "is_executing": true
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from secml.figure import CFigure\n",
    "\n",
    "fig = CFigure()\n",
    "fig.sp.plot(partial_dos.confidences_, label='dos')\n",
    "fig.sp.plot(ifgsm.confidences_, label='kreuk')\n",
    "fig.sp.plot([0, 10], [0.5, 0.5], label='threshold', linestyle='--', c='r')\n",
    "fig.sp.xlabel('Iterations')\n",
    "fig.sp.ylabel('Malware class confidence')\n",
    "fig.sp.legend()\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "As you notice, the attacks behave differently. Can you guess why?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Gradient-free evasion of Windows Malware Detectors\n",
    "\n",
    "We move to gradient-free approaches, and we will leverage optimisation of adversarial content injected through new sections inside the input executable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "is_executing": true
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import magic\n",
    "import numpy as np\n",
    "from secml.array import CArray\n",
    "\n",
    "from secml_malware.attack.blackbox.c_wrapper_phi import CEnd2EndWrapperPhi\n",
    "from secml_malware.attack.blackbox.ga.c_base_genetic_engine import CGeneticAlgorithm\n",
    "from secml_malware.models.c_classifier_end2end_malware import CClassifierEnd2EndMalware\n",
    "from secml_malware.models.malconv import MalConv\n",
    "\n",
    "net = CClassifierEnd2EndMalware(MalConv())\n",
    "net.load_pretrained_model()\n",
    "net = CEnd2EndWrapperPhi(net)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Firstly, we have created the network (MalConv) and it has been passed wrapped with a *CClassifierEnd2EndMalware* model class.\n",
    "Since MalConv is already coded inside the plugin, the weights are also stored, and they can be retrieved with the *load_pretrained_model* method.\n",
    "\n",
    "If you wish to use diffierent weights, pass the path to the PyTorch *pth* file to that method.\n",
    "\n",
    "Then, we wrap it inside a `CEnd2EndWrapperPhi`, that is an interface that abstracts from the feature extraction phase of the model.\n",
    "This is needed for the black-box settings of the attack.\n",
    "\n",
    "We will start by optimizing byte-per-byte through the injection of padding bytes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "is_executing": true
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Importa la libreria numpy per la manipolazione degli array\n",
    "import numpy as np\n",
    "\n",
    "# Definisce la cartella contenente i file eseguibili\n",
    "folder = 'exe'\n",
    "\n",
    "# Inizializza le liste per i dati di input, le etichette e i nomi dei file\n",
    "X_gf = []\n",
    "y_gf = []\n",
    "file_names_gf = []\n",
    "\n",
    "# Itera su tutti i file nella cartella specificata\n",
    "for i, f in enumerate(os.listdir(folder)):\n",
    "    # Costruisce il percorso completo del file\n",
    "    path = os.path.join(folder, f)\n",
    "    \n",
    "    # Verifica se il percorso è un file, altrimenti continua con il prossimo file\n",
    "    if not os.path.isfile(path):\n",
    "        continue\n",
    "    \n",
    "    # Verifica se il file è un eseguibile PE32, altrimenti continua con il prossimo file\n",
    "    if \"PE32\" not in magic.from_file(path):\n",
    "        continue\n",
    "    \n",
    "    # Legge il contenuto del file in modalità binaria\n",
    "    with open(path, \"rb\") as file_handle:\n",
    "        code = file_handle.read()\n",
    "    \n",
    "    # Converte il contenuto del file in un array CArray utilizzando numpy\n",
    "    x = CArray(np.frombuffer(code, dtype=np.uint8))\n",
    "    \n",
    "    # Predice la probabilità di malware e ottiene la confidenza\n",
    "    _, confidence = net.predict(x, True)\n",
    "\n",
    "    # Se la confidenza è inferiore a 0.5, continua con il prossimo file\n",
    "    if confidence[0, 1].item() < 0.5:\n",
    "        continue\n",
    "\n",
    "    # Stampa il nome del file aggiunto e la sua confidenza\n",
    "    print(f\"> Added {f} with confidence {confidence[0,1].item()}\")\n",
    "    \n",
    "    # Aggiunge l'array CArray alla lista degli input\n",
    "    X_gf.append(x)\n",
    "    \n",
    "    # Aggiunge l'etichetta alla lista delle etichette (1 indica malware)\n",
    "    y_gf.append(1)\n",
    "    \n",
    "    # Aggiunge il percorso del file alla lista dei nomi dei file\n",
    "    file_names_gf.append(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "is_executing": true
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Importa l'attacco blackbox CBlackBoxPaddingEvasionProblem dalla libreria secml_malware\n",
    "from secml_malware.attack.blackbox.c_black_box_padding_evasion import CBlackBoxPaddingEvasionProblem\n",
    "\n",
    "# Importa l'algoritmo genetico CGeneticAlgorithm dalla libreria secml_malware\n",
    "from secml_malware.attack.blackbox.ga.c_base_genetic_engine import CGeneticAlgorithm\n",
    "\n",
    "# Crea un'istanza dell'attacco CBlackBoxPaddingEvasionProblem con i parametri specificati\n",
    "attack_padding = CBlackBoxPaddingEvasionProblem(net, population_size=10, penalty_regularizer=1e-6, iterations=500, how_many_padding_bytes=4096)\n",
    "\n",
    "# Crea un'istanza dell'algoritmo genetico con l'attacco specificato\n",
    "engine = CGeneticAlgorithm(attack_padding)\n",
    "\n",
    "# Itera su ogni campione e etichetta nei dati di input e nelle etichette\n",
    "for sample, label in zip(X_gf, y_gf):\n",
    "    # Esegue l'attacco genetico sul campione e ottiene la previsione, il punteggio avversario, il dataset avversario e l'oggetto funzione\n",
    "    y_pred, adv_score, adv_ds, f_obj = engine.run(sample, label)\n",
    "    \n",
    "    # Stampa le confidenze dell'attacco\n",
    "    print(engine.confidences_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Under the hood, the attack is optimizing each the 4096 bytes, one by one. To speed up the process, we can inject chunks of goodware content, and let the optimizer decide how much to extract."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "is_executing": true
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from secml_malware.attack.blackbox.c_gamma_sections_evasion import CGammaSectionsEvasionProblem\n",
    "goodware_folder = 'exe/goodware'\n",
    "section_population, what_from_who = CGammaSectionsEvasionProblem.create_section_population_from_folder(goodware_folder, how_many=10, sections_to_extract=['.rdata'])\n",
    "\n",
    "gamma_attack = CGammaSectionsEvasionProblem(section_population, net, population_size=10, penalty_regularizer=1e-6, iterations=100, threshold=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "For the section injection attack implemented with GAMMA, we need first to extract the goodware sections.\n",
    "Then, we create a `CGammaSectionsEvasionProblem` object, that contains the attack."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "is_executing": true
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "engine_gamma = CGeneticAlgorithm(gamma_attack)\n",
    "for sample, label in zip(X, y):\n",
    "    y_pred, adv_score, adv_ds, f_obj = engine_gamma.run(sample, CArray(label[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Inside the `adv_ds` object, you can find the adversarial example computed by the attack.\n",
    "You can reconstruct the functioning example by using a specific function inside the plugin:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "is_executing": true
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "adv_x = adv_ds.X[0,:]\n",
    "engine_gamma.write_adv_to_file(adv_x,'adv_exe')\n",
    "with open('adv_exe', 'rb') as h:\n",
    "    code = h.read()\n",
    "real_adv_x = CArray(np.frombuffer(code, dtype=np.uint8))\n",
    "_, confidence = net.predict(CArray(real_adv_x), True)\n",
    "print(confidence[0,1].item())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "... and you're done!\n",
    "If you want to create a real sample (stored on disk), just have a look at the `create_real_sample_from_adv` of each attack. It accepts a third string argument that will be used as a destination file path for storing the adversarial example."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
